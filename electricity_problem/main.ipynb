{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a950ba5c-137e-4e49-9781-568a9e86908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *\n",
    "from solver import SolveScheduling\n",
    "from get_data import *\n",
    "from train import * \n",
    "from models import *\n",
    "from projectnet import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cffdbde1-9d0b-4b9a-9bfe-191c3c2640c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"n\": 24, \"c_ramp\": 0.4, \"gamma_under\": 50, \"gamma_over\": 0.5}\n",
    "scheduling_solver = SolvePointQP(params)\n",
    "dist_solver = SolveScheduling(params)\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, X_train_pt, Y_train_pt, X_test_pt, Y_test_pt = get_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff2aab5-bd3f-4a4a-99a7-aa57e443198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = scheduling_solver.G[24*2:24*2+23*2,:]\n",
    "A = torch.cat((G, torch.eye(G.shape[0]).to(DEVICE)), dim=1).float().to(DEVICE)\n",
    "b = params['c_ramp'] * torch.ones((24 - 1)*2, device=DEVICE).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90155a03-142b-434b-a48f-43d7e303f010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46, 118]) torch.Size([46])\n"
     ]
    }
   ],
   "source": [
    "print(A.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5ce4b2-dd4b-48d4-b96e-9bdf6e027fd6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  mean loss:  1.1017354394380863  median  1.0509483218193054 cur:  0.8622184991836548\n",
      "epoch  1  mean loss:  0.9571446770429611  median  0.941331684589386 cur:  0.6837594509124756\n",
      "epoch  2  mean loss:  0.7941359728574753  median  0.8484386801719666 cur:  0.7007178068161011\n",
      "epoch  3  mean loss:  0.7236167746782303  median  0.8097432851791382 cur:  0.5807981491088867\n",
      "epoch  4  mean loss:  0.6688397830724716  median  0.7655080854892731 cur:  0.5104993581771851\n",
      "epoch  5  mean loss:  0.582694853246212  median  0.7079532742500305 cur:  0.4150388240814209\n",
      "epoch  6  mean loss:  0.49595375657081603  median  0.684368908405304 cur:  0.44040292501449585\n",
      "epoch  7  mean loss:  0.5047060745954514  median  0.662131667137146 cur:  0.44454240798950195\n",
      "epoch  8  mean loss:  0.5292767044901848  median  0.6324037611484528 cur:  0.46450942754745483\n",
      "epoch  9  mean loss:  0.4757129240036011  median  0.6030329763889313 cur:  0.36275070905685425\n",
      "epoch  10  mean loss:  0.4041717004776001  median  0.580399215221405 cur:  0.32830920815467834\n",
      "epoch  11  mean loss:  0.35964116334915164  median  0.5461952686309814 cur:  0.3233095109462738\n",
      "epoch  12  mean loss:  0.34075151741504667  median  0.5277235209941864 cur:  0.3107341229915619\n",
      "epoch  13  mean loss:  0.3541411179304123  median  0.5104377269744873 cur:  0.32017675042152405\n",
      "epoch  14  mean loss:  0.33943377375602724  median  0.495032474398613 cur:  0.2697511315345764\n",
      "epoch  15  mean loss:  0.2877091683447361  median  0.4766712337732315 cur:  0.26201942563056946\n",
      "epoch  16  mean loss:  0.2701482307910919  median  0.45943930745124817 cur:  0.2610463798046112\n",
      "epoch  17  mean loss:  0.26569306194782255  median  0.43841058015823364 cur:  0.2602285146713257\n",
      "epoch  18  mean loss:  0.2371431328356266  median  0.4216547906398773 cur:  0.21802151203155518\n",
      "epoch  19  mean loss:  0.22658444285392762  median  0.40385839343070984 cur:  0.21489213407039642\n",
      "epoch  20  mean loss:  0.21791692748665809  median  0.39014169573783875 cur:  0.2363993227481842\n",
      "epoch  21  mean loss:  0.20443901062011718  median  0.37512022256851196 cur:  0.19988450407981873\n",
      "epoch  22  mean loss:  0.2022359138727188  median  0.36677880585193634 cur:  0.18647007644176483\n",
      "epoch  23  mean loss:  0.2032514889538288  median  0.35657960176467896 cur:  0.21271395683288574\n",
      "epoch  24  mean loss:  0.19910720750689506  median  0.3453626483678818 cur:  0.18136081099510193\n",
      "epoch  25  mean loss:  0.18274620920419693  median  0.337231770157814 cur:  0.16435818374156952\n",
      "epoch  26  mean loss:  0.16807278156280517  median  0.32331623136997223 cur:  0.1658616065979004\n",
      "epoch  27  mean loss:  0.14772106915712357  median  0.31263376772403717 cur:  0.09981481730937958\n",
      "epoch  28  mean loss:  0.0969031511247158  median  0.30335474014282227 cur:  0.04750990867614746\n",
      "epoch  29  mean loss:  0.060688876137137415  median  0.29273761808872223 cur:  0.048226188868284225\n",
      "epoch  30  mean loss:  0.047307694982737306  median  0.282226100564003 cur:  0.028839942067861557\n",
      "epoch  31  mean loss:  0.03336753124371171  median  0.2742246687412262 cur:  0.02560417726635933\n",
      "epoch  32  mean loss:  0.028045128360390664  median  0.26223208010196686 cur:  0.02064981311559677\n",
      "epoch  33  mean loss:  0.02464530136436224  median  0.25586894154548645 cur:  0.022820379585027695\n",
      "epoch  34  mean loss:  0.02308674555271864  median  0.24701077491044998 cur:  0.018778078258037567\n",
      "epoch  35  mean loss:  0.02178454098291695  median  0.23939546197652817 cur:  0.01832759566605091\n",
      "epoch  36  mean loss:  0.020924251889809967  median  0.23252636939287186 cur:  0.016884328797459602\n",
      "epoch  37  mean loss:  0.020143690621480345  median  0.22583384066820145 cur:  0.020464040338993073\n",
      "epoch  38  mean loss:  0.022481145216152073  median  0.2228197157382965 cur:  0.01942630298435688\n",
      "epoch  39  mean loss:  0.022780695240944625  median  0.21822921931743622 cur:  0.015666311606764793\n",
      "epoch  40  mean loss:  0.0195190385915339  median  0.2144358605146408 cur:  0.016101891174912453\n",
      "epoch  41  mean loss:  0.019562121238559483  median  0.209875650703907 cur:  0.02036670781672001\n",
      "epoch  42  mean loss:  0.020292171351611613  median  0.20621930062770844 cur:  0.016056593507528305\n",
      "epoch  43  mean loss:  0.019489639569073916  median  0.20365124940872192 cur:  0.01529371552169323\n",
      "epoch  44  mean loss:  0.018968937210738657  median  0.20067892223596573 cur:  0.01594088226556778\n",
      "epoch  45  mean loss:  0.018819120256230237  median  0.19675032049417496 cur:  0.017230091616511345\n",
      "epoch  46  mean loss:  0.018253735145553947  median  0.19395604729652405 cur:  0.017203353345394135\n",
      "epoch  47  mean loss:  0.018180222865194082  median  0.19052009284496307 cur:  0.016847241669893265\n",
      "epoch  48  mean loss:  0.017723314240574838  median  0.18596883863210678 cur:  0.01615460403263569\n",
      "epoch  49  mean loss:  0.016879208851605654  median  0.1789439469575882 cur:  0.015779051929712296\n",
      "MEAN LOSS PROJECT NET:  0.016879208851605654\n"
     ]
    }
   ],
   "source": [
    "rounds = 5\n",
    "projectnet = ProjectNet(A, b, 24, rounds=rounds).to(DEVICE)\n",
    "train_projectnet(projectnet, Y_train_pt, params, epochs=50, verbose=True) \n",
    "torch.save(projectnet.state_dict(), \"projectnet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c2063c5-bfc5-4648-a589-d2852252b9a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  mean loss:  1.8001214816020086 time 1.940086841583252\n",
      "epoch  1  mean loss:  1.1464905406420047 time 1.9724336862564087\n",
      "epoch  2  mean loss:  0.8752684031541531 time 2.0483574072519937\n",
      "epoch  3  mean loss:  0.6355864295363426 time 2.089836597442627\n",
      "epoch  4  mean loss:  0.3376831120252609 time 2.106196403503418\n",
      "epoch  5  mean loss:  0.29158531248569486 time 2.0806414683659873\n",
      "epoch  6  mean loss:  0.27452532440423966 time 2.0781772136688232\n",
      "epoch  7  mean loss:  0.26750762611627577 time 2.0620470345020294\n",
      "epoch  8  mean loss:  0.2611908197402954 time 2.0472243626912436\n",
      "epoch  9  mean loss:  0.2566872188448906 time 2.0408398389816282\n",
      "epoch  10  mean loss:  0.2543268083035946 time 2.026160782033747\n",
      "epoch  11  mean loss:  0.25087924718856813 time 2.013754586378733\n",
      "epoch  12  mean loss:  0.24938320338726044 time 1.9982930696927583\n",
      "epoch  13  mean loss:  0.24677032947540284 time 1.9906443527766637\n",
      "epoch  14  mean loss:  0.24469002157449724 time 1.991917896270752\n",
      "epoch  15  mean loss:  0.2418687392771244 time 1.9853536486625671\n",
      "epoch  16  mean loss:  0.23939472332596778 time 1.9816610111909754\n",
      "epoch  17  mean loss:  0.23670017063617707 time 1.978314717610677\n",
      "epoch  18  mean loss:  0.23459107413887978 time 1.973746425227115\n",
      "epoch  19  mean loss:  0.23377895906567572 time 1.9680296301841735\n",
      "epoch  20  mean loss:  0.2314216335117817 time 1.966344220297677\n",
      "epoch  21  mean loss:  0.22965207755565642 time 1.9661076827482744\n",
      "epoch  22  mean loss:  0.2290589126944542 time 1.9601091509279998\n",
      "epoch  23  mean loss:  0.22586484730243683 time 1.9530749519666035\n",
      "epoch  24  mean loss:  0.22371777817606925 time 1.9495674324035646\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_pnet \u001b[38;5;241m=\u001b[39m Net(X_train[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], Y_train, [\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m200\u001b[39m])\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_with_pnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_pnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprojectnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_pt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_pt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_pnet\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_pnet.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Rares/projectnet/electricity_problem/train.py:64\u001b[0m, in \u001b[0;36mtrain_with_pnet\u001b[0;34m(model, projectnet, train_x, train_y, params, rounds, map_size, batch_size, epochs, lr, verbose)\u001b[0m\n\u001b[1;32m     61\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     63\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 64\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mprojectnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m loss \u001b[38;5;241m=\u001b[39m task_loss(pred, y, params)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     67\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/my-conda-envs/rares_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my-conda-envs/rares_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Rares/projectnet/electricity_problem/projectnet.py:105\u001b[0m, in \u001b[0;36mProjectNet.forward\u001b[0;34m(self, c, rounds, tol, xrho, factor, fixed)\u001b[0m\n\u001b[1;32m    102\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(x, c, xrho, rho)\n\u001b[1;32m    104\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, torch\u001b[38;5;241m.\u001b[39mzeros(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(DEVICE)), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\u001b[38;5;241m.\u001b[39mfloat()            \n\u001b[0;32m--> 105\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mproject_pol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m[:,:\u001b[38;5;241m24\u001b[39m]\n\u001b[1;32m    106\u001b[0m rho \u001b[38;5;241m=\u001b[39m rho \u001b[38;5;241m*\u001b[39m factor\n\u001b[1;32m    107\u001b[0m xrho \u001b[38;5;241m=\u001b[39m xrho \u001b[38;5;241m*\u001b[39m factor\n",
      "File \u001b[0;32m~/Rares/projectnet/electricity_problem/projectnet.py:33\u001b[0m, in \u001b[0;36mproject_pol\u001b[0;34m(P, A, b, x, DEVICE, n, AA, tol, offset)\u001b[0m\n\u001b[1;32m     31\u001b[0m y \u001b[38;5;241m=\u001b[39m project(A, b, x \u001b[38;5;241m+\u001b[39m p, AA \u001b[38;5;241m=\u001b[39m AA)\n\u001b[1;32m     32\u001b[0m p \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m p \u001b[38;5;241m-\u001b[39m y       \n\u001b[0;32m---> 33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m q \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m q \u001b[38;5;241m-\u001b[39m x\n\u001b[1;32m     36\u001b[0m err \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;241m-\u001b[39my))\n",
      "File \u001b[0;32m~/my-conda-envs/rares_env/lib/python3.12/site-packages/torch/nn/functional.py:1489\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1477\u001b[0m threshold \u001b[38;5;241m=\u001b[39m _threshold\n\u001b[1;32m   1479\u001b[0m threshold_ \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   1480\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mthreshold_,\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m,\n\u001b[1;32m   1486\u001b[0m )\n\u001b[0;32m-> 1489\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelu\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, inplace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:  \u001b[38;5;66;03m# noqa: D400,D402\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"relu(input, inplace=False) -> Tensor\u001b[39;00m\n\u001b[1;32m   1491\u001b[0m \n\u001b[1;32m   1492\u001b[0m \u001b[38;5;124;03m    Applies the rectified linear unit function element-wise. See\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;124;03m    :class:`~torch.nn.ReLU` for more details.\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_pnet = Net(X_train[:,:-1], Y_train, [200,200]).to(DEVICE)\n",
    "train_with_pnet(model_pnet, projectnet, X_train_pt, Y_train_pt, params, rounds=rounds, epochs=100, lr=1e-4)\n",
    "torch.save(model_pnet.state_dict(), \"model_pnet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e8141f0-770c-41ae-9ccc-a617bb247e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_(model):\n",
    "    with torch.no_grad():\n",
    "        p = model(X_test_pt)\n",
    "        costs = []\n",
    "        for i in range(p.shape[0]):\n",
    "            d = projectnet(p[i:i+1,:], tol=1e-4).detach()\n",
    "            c = task_loss(d, Y_test_pt[i:i+1,:], params).mean()\n",
    "            costs.append(c.item())\n",
    "    return costs\n",
    "\n",
    "def evaluate_task(model):\n",
    "    with torch.no_grad():\n",
    "        m,s = model(X_test_pt)\n",
    "        costs = []\n",
    "        for i in range(m.shape[0]):\n",
    "            d = dist_solver(m[i:i+1,:],s[i:i+1,:]).detach()\n",
    "            c = task_loss(d, Y_test_pt[i:i+1,:], params).mean()\n",
    "            costs.append(c.item())\n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60548508-2652-4256-9bac-1be8bf248639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test pnet costs: 0.24061602905555884\n"
     ]
    }
   ],
   "source": [
    "pnet_costs = evaluate_(model_pnet)\n",
    "print(\"Test pnet costs:\", np.mean(pnet_costs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dddde1dd-3211-47a4-960b-4c49c0956d92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.8264765398842948 times: 21.501551866531372\n",
      "epoch: 1 loss: 0.8239014077754248 times: 21.141249299049377\n",
      "epoch: 2 loss: 0.822628118689098 times: 21.188942193984985\n",
      "epoch: 3 loss: 0.8219292561213175 times: 21.07893842458725\n",
      "epoch: 4 loss: 0.8216588753461838 times: 21.048382806777955\n",
      "epoch: 5 loss: 0.8211283278465271 times: 20.926042437553406\n",
      "epoch: 6 loss: 0.8209739810228348 times: 21.096338238034928\n",
      "epoch: 7 loss: 0.8212644195556641 times: 21.23966908454895\n",
      "epoch: 8 loss: 0.8215325736999511 times: 21.128661764992607\n",
      "epoch: 9 loss: 0.8213019561767578 times: 21.128051471710204\n",
      "epoch: 10 loss: 0.8211598724126816 times: 21.21417381546714\n",
      "epoch: 11 loss: 0.821280118227005 times: 21.256215155124664\n",
      "epoch: 12 loss: 0.8214086413383483 times: 21.146953105926514\n",
      "epoch: 13 loss: 0.8216732960939407 times: 21.103920068059647\n",
      "epoch: 14 loss: 0.8217941355705262 times: 21.06352915763855\n",
      "epoch: 15 loss: 0.8217969489097595 times: 21.088600546121597\n",
      "epoch: 16 loss: 0.8216940528154373 times: 21.122121614568375\n",
      "epoch: 21 loss: 0.8211093616485595 times: 21.2925007018176\n",
      "epoch: 22 loss: 0.8204433351755143 times: 21.258962745251864\n",
      "epoch: 23 loss: 0.8206134235858917 times: 21.229860772689182\n",
      "epoch: 24 loss: 0.8204433000087739 times: 21.216608457565307\n",
      "epoch: 25 loss: 0.8208100968599319 times: 21.199275677020733\n",
      "epoch: 26 loss: 0.8207232087850571 times: 21.181549893485176\n",
      "epoch: 27 loss: 0.8210251355171203 times: 21.1753636768886\n",
      "epoch: 28 loss: 0.8213473552465439 times: 21.25369954109192\n",
      "epoch: 29 loss: 0.8218139892816544 times: 21.262692268689474\n",
      "epoch: 30 loss: 0.8221124070882797 times: 21.23071135244062\n",
      "epoch: 31 loss: 0.8223330599069595 times: 21.288255251944065\n",
      "epoch: 32 loss: 0.8225186365842819 times: 21.235215295444835\n",
      "epoch: 33 loss: 0.8221936881542206 times: 21.165854608311374\n",
      "epoch: 34 loss: 0.8214820182323456 times: 21.163862889153616\n",
      "epoch: 35 loss: 0.8212116849422455 times: 21.220863646931118\n",
      "epoch: 36 loss: 0.8212593120336532 times: 21.201541468903827\n",
      "epoch: 37 loss: 0.8212774628400803 times: 21.201551305620296\n",
      "epoch: 38 loss: 0.8209313064813614 times: 21.19334199489691\n",
      "epoch: 39 loss: 0.8214339900016785 times: 21.25326461195946\n",
      "epoch: 40 loss: 0.8211719661951065 times: 21.23947901260562\n",
      "epoch: 41 loss: 0.8212336611747741 times: 21.25667639573415\n",
      "epoch: 42 loss: 0.8213553446531295 times: 21.261146190554598\n",
      "epoch: 43 loss: 0.8216154724359512 times: 21.223628304221414\n",
      "epoch: 44 loss: 0.8216099506616592 times: 21.28099094496833\n",
      "epoch: 45 loss: 0.8214283454418182 times: 21.306999481242634\n",
      "epoch: 46 loss: 0.8212912327051163 times: 21.289626786049375\n",
      "epoch: 47 loss: 0.8215169906616211 times: 21.26479225854079\n",
      "epoch: 48 loss: 0.8215221500396729 times: 21.2561481631532\n",
      "epoch: 49 loss: 0.8213569951057434 times: 21.252316255569458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net2(\n",
       "  (lin): Linear(in_features=149, out_features=24, bias=True)\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=149, out_features=200, bias=True)\n",
       "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (5): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=200, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_net = Net2(X_train[:,:-1], Y_train, [200,200]).to(DEVICE)\n",
    "train_task_net(task_net, params, X_train_pt, Y_train_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95830799-5aba-45a6-a60c-321ea2adf711",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_costs = evaluate_task(task_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56153e3b-1d70-4a5f-b994-91b6d14b151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test task costs: 0.8804126808834132\n"
     ]
    }
   ],
   "source": [
    "print(\"Test task costs:\", np.mean(task_costs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be17bc7-deb4-4e74-9081-566fcc501f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rares_env",
   "language": "python",
   "name": "rares_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
