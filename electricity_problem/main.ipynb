{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a950ba5c-137e-4e49-9781-568a9e86908e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "from solver import SolveScheduling\n",
    "from get_data import *\n",
    "from train import * \n",
    "from models import *\n",
    "from projectnet import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from exact_regularizer import RegApproximator\n",
    "from parameters import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cffdbde1-9d0b-4b9a-9bfe-191c3c2640c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"n\": 24, \"c_ramp\": 0.4, \"gamma_under\": 50, \"gamma_over\": 0.5}\n",
    "scheduling_solver = SolvePointQP(params)\n",
    "dist_solver = SolveScheduling(params)\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, X_train_pt, Y_train_pt, X_test_pt, Y_test_pt = get_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d4bd01-2a35-4952-b071-18df7b0a6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_loss_no_quad(Y_sched, Y_actual, params):\n",
    "    return (params[\"gamma_under\"] * torch.clamp(Y_actual - Y_sched, min=0) + \n",
    "            params[\"gamma_over\"] * torch.clamp(Y_sched - Y_actual, min=0)).mean()\n",
    "def task_loss(Y_sched, Y_actual, params):\n",
    "    return (params[\"gamma_under\"] * torch.clamp(Y_actual - Y_sched, min=0) + \n",
    "            params[\"gamma_over\"] * torch.clamp(Y_sched - Y_actual, min=0) + 0.5 * torch.square(Y_sched - Y_actual)).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff2aab5-bd3f-4a4a-99a7-aa57e443198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = scheduling_solver.G[24*2:24*2+23*2,:]\n",
    "A = torch.cat((G, torch.eye(G.shape[0]).to(DEVICE)), dim=1).float().to(DEVICE)\n",
    "b = params['c_ramp'] * torch.ones((24 - 1)*2, device=DEVICE).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "005d9d1a-19a5-4c09-8083-b55a114fe8db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lin): Linear(in_features=149, out_features=24, bias=True)\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=149, out_features=200, bias=True)\n",
       "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (5): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=200, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mle_net = Net(X_train[:,:-1], Y_train, [200,200]).to(DEVICE)\n",
    "train_mle_net(mle_net, params, X_train_pt, Y_train_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53457211-3203-4aaa-b7a8-619f3fbeb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pt = mle_net(X_train_pt).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "365cf31f-54b9-4845-ae18-4d8e5f24e390",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  mean loss:  0.17587868267526993  median  0.16457729786634445 cur:  0.147096648812294\n",
      "epoch  1  mean loss:  0.17299401879310608  median  0.16300896555185318 cur:  0.14896747469902039\n",
      "epoch  2  mean loss:  0.17055035635828972  median  0.1635834500193596 cur:  0.12840333580970764\n",
      "epoch  3  mean loss:  0.169000031799078  median  0.1614476963877678 cur:  0.14407867193222046\n",
      "epoch  4  mean loss:  0.16743785083293916  median  0.15960760414600372 cur:  0.12963877618312836\n",
      "epoch  5  mean loss:  0.1661447298526764  median  0.1593332216143608 cur:  0.12966853380203247\n",
      "epoch  6  mean loss:  0.1657095442712307  median  0.159199520945549 cur:  0.12857624888420105\n",
      "epoch  7  mean loss:  0.16566627085208893  median  0.1590614691376686 cur:  0.14176926016807556\n",
      "epoch  8  mean loss:  0.16517056576907635  median  0.1587136834859848 cur:  0.12147196382284164\n",
      "epoch  9  mean loss:  0.1643104577809572  median  0.1580636128783226 cur:  0.14515827596187592\n",
      "epoch  10  mean loss:  0.16395485535264015  median  0.15745694935321808 cur:  0.1397884637117386\n",
      "epoch  11  mean loss:  0.16292744792997838  median  0.15696340799331665 cur:  0.12084891647100449\n",
      "epoch  12  mean loss:  0.16137134693562985  median  0.15619249641895294 cur:  0.12035326659679413\n",
      "epoch  13  mean loss:  0.16130184777081014  median  0.15606793016195297 cur:  0.14193755388259888\n",
      "epoch  14  mean loss:  0.16180150128901005  median  0.15586383640766144 cur:  0.12288280576467514\n",
      "epoch  15  mean loss:  0.16139847680926322  median  0.15576095134019852 cur:  0.12391134351491928\n",
      "epoch  16  mean loss:  0.16052968211472035  median  0.15560418367385864 cur:  0.14104335010051727\n",
      "epoch  17  mean loss:  0.1604604233801365  median  0.15556569397449493 cur:  0.12086274474859238\n",
      "epoch  18  mean loss:  0.15995709702372551  median  0.15540148317813873 cur:  0.12229707092046738\n",
      "epoch  19  mean loss:  0.15887082941830158  median  0.15524209290742874 cur:  0.12273570150136948\n",
      "epoch  20  mean loss:  0.15895068041980268  median  0.1548534482717514 cur:  0.12060599774122238\n",
      "epoch  21  mean loss:  0.15853742502629756  median  0.1545327827334404 cur:  0.12158292531967163\n",
      "epoch  22  mean loss:  0.15893448323011397  median  0.15435729920864105 cur:  0.13864316046237946\n",
      "epoch  23  mean loss:  0.15930489495396613  median  0.15430062264204025 cur:  0.12982267141342163\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m learn_pnet \u001b[38;5;241m=\u001b[39m ProjectNet(A, b, \u001b[38;5;241m24\u001b[39m, params, rounds\u001b[38;5;241m=\u001b[39mrounds, step\u001b[38;5;241m=\u001b[39mstep_size)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_projectnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn_pnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_pt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Rares/projectnet/electricity_problem/train.py:38\u001b[0m, in \u001b[0;36mtrain_projectnet\u001b[0;34m(model, Y_actual, params, epochs, rounds, lr, verbose)\u001b[0m\n\u001b[1;32m     35\u001b[0m y \u001b[38;5;241m=\u001b[39m Y_actual[i:i\u001b[38;5;241m+\u001b[39mbatch_size,:]\n\u001b[1;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 38\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m task_loss(outputs, y, params)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     42\u001b[0m cur_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/my-conda-envs/rares_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my-conda-envs/rares_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Rares/projectnet/electricity_problem/projectnet.py:118\u001b[0m, in \u001b[0;36mProjectNet.forward\u001b[0;34m(self, c, rounds, tol, xrho, factor, learn)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(x, c, xrho, rho)\n\u001b[0;32m--> 118\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(DEVICE)), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\u001b[38;5;241m.\u001b[39mfloat()            \n\u001b[1;32m    119\u001b[0m x \u001b[38;5;241m=\u001b[39m project_pol(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb, x, DEVICE, AA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAA, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_count, tol \u001b[38;5;241m=\u001b[39m tol, offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)[:,:\u001b[38;5;241m24\u001b[39m]\n\u001b[1;32m    120\u001b[0m rho \u001b[38;5;241m=\u001b[39m rho \u001b[38;5;241m*\u001b[39m factor\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn_pnet = ProjectNet(A, b, 24, params, rounds=rounds, step=step_size).to(DEVICE)\n",
    "train_projectnet(learn_pnet, Y_train_pt, params, lr=1e-3, epochs=500, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f240557-a465-446d-9258-513e8c7580ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt_solutions = []\n",
    "batch_size = 10\n",
    "for k in range(0, (Y_train_pt.shape[0] // batch_size) * batch_size, batch_size):\n",
    "    d = scheduling_solver(Y_train_pt[k:k+batch_size,:]).detach().cpu().numpy()\n",
    "    opt_solutions.append(d)\n",
    "opt_solutions = np.array(opt_solutions)\n",
    "opt_solutions = np.array(opt_solutions).reshape(opt_solutions.shape[0] * opt_solutions.shape[1], 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5344f89-9c7d-4531-8e21-ae2529584868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca9ed597-c17b-4fa6-8c06-7b01963b39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_approximator = RegApproximator(opt_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07825c7e-5958-4bba-b9d4-a3cca45cae7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alpha = 0.1\n",
    "# reg_approximator.linear_par(alpha, beta, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0656ad8-51ed-4560-acaf-5038cbf01449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "beta = 0.2\n",
    "opt_L = reg_approximator.get_quadratic_regularizer(alpha, beta, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aeb93cd7-4589-4634-9073-1c879cfc7286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.round(opt_L, 4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f385fe2-3e16-405c-a016-16ae0b5e1fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000064810702265"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.cond(opt_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ba1f4dc-7a73-46e1-99ec-14935c299f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rho = 0.005\n",
    "\n",
    "projectnet = ProjectNet(A, b, 24, params, rounds=100).to(DEVICE)\n",
    "projectnet.Q = torch.tensor(opt_L).to(DEVICE).float()\n",
    "projectnet.rho = rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6af27888-d7f0-458e-9fa9-8bf8bf4b1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_fast = []\n",
    "losses_vanilla = []\n",
    "losses_learn = []\n",
    "rs = range(5,20, 1)\n",
    "l_rs = range(1,6)\n",
    "\n",
    "for rounds in rs:\n",
    "    outs = projectnet(Y_train_pt, rounds=rounds, xrho=0)\n",
    "    l_vanilla = task_loss_no_quad(outs, Y_train_pt, params)\n",
    "    \n",
    "    outs = projectnet(Y_train_pt, rounds=rounds, xrho=rho)\n",
    "    l = task_loss_no_quad(outs, Y_train_pt, params)\n",
    "    \n",
    "    losses_fast.append(l.item())\n",
    "    losses_vanilla.append(l_vanilla.item())\n",
    "\n",
    "for rounds in l_rs:\n",
    "    outs = learn_pnet(Y_train_pt, rounds=rounds, learn=True)\n",
    "    learn_l = task_loss_no_quad(outs, Y_train_pt, params)\n",
    "    losses_learn.append(learn_l.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d2d290b-132c-4523-9f4c-83c7f13eb5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rs, losses_fast, label='reg')\n",
    "plt.plot(rs, losses_vanilla, label='vanilla')\n",
    "plt.plot([0,10], [losses_learn[-1],losses_learn[-1]] , label='learn')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2604ba-93a8-45a3-b750-497a040e951f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc45933-c4f5-4d90-8212-21f6a9402725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d4ee9f1-35bb-44ad-b7e6-c1cf723d5147",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.17920169979333878 times: 0.3297889232635498\n",
      "epoch: 1 loss: 0.15260260853056723 times: 0.22669458389282227\n",
      "epoch: 2 loss: 0.13717754070575422 times: 0.19279257456461588\n",
      "epoch: 3 loss: 0.12293945744633675 times: 0.17633122205734253\n",
      "epoch: 4 loss: 0.10247148722410201 times: 0.16598954200744628\n",
      "epoch: 5 loss: 0.09139559432864189 times: 0.15850265820821127\n",
      "epoch: 6 loss: 0.08432182785123586 times: 0.152796847479684\n",
      "epoch: 7 loss: 0.07917161662131549 times: 0.14940640330314636\n",
      "epoch: 8 loss: 0.07453170385211706 times: 0.14724318186442056\n",
      "epoch: 9 loss: 0.07093202453106642 times: 0.1444946527481079\n",
      "epoch: 10 loss: 0.06707410674542189 times: 0.14248830621892755\n",
      "epoch: 11 loss: 0.06395286597311496 times: 0.14069845279057822\n",
      "epoch: 12 loss: 0.06120778292417526 times: 0.1396648333622859\n",
      "epoch: 13 loss: 0.05867682598531246 times: 0.1384709051677159\n",
      "epoch: 14 loss: 0.05686978280544281 times: 0.1373550573984782\n",
      "epoch: 15 loss: 0.05479804515838623 times: 0.13629025220870972\n",
      "epoch: 16 loss: 0.052769207879900935 times: 0.13530891081866095\n",
      "epoch: 17 loss: 0.05114163387566805 times: 0.13452222612169054\n",
      "epoch: 18 loss: 0.04937836293131113 times: 0.13390261248538368\n",
      "epoch: 19 loss: 0.04808516938239336 times: 0.13320376873016357\n",
      "epoch: 20 loss: 0.046424227952957156 times: 0.13269750277201334\n",
      "epoch: 21 loss: 0.04503218963742256 times: 0.13215865872123025\n",
      "epoch: 22 loss: 0.043328955247998235 times: 0.1317371700121009\n",
      "epoch: 23 loss: 0.042307302951812745 times: 0.13134889801343283\n",
      "epoch: 24 loss: 0.04085984017699957 times: 0.13097772598266602\n",
      "epoch: 25 loss: 0.03929810268804431 times: 0.13066024963672346\n",
      "epoch: 26 loss: 0.03834462430328131 times: 0.1304902500576443\n",
      "epoch: 27 loss: 0.036769401244819165 times: 0.13031941652297974\n",
      "epoch: 28 loss: 0.03599975157529116 times: 0.1301067615377492\n",
      "epoch: 29 loss: 0.03491113096475601 times: 0.1297272284825643\n",
      "epoch: 30 loss: 0.034177122339606285 times: 0.12928810427265783\n",
      "epoch: 31 loss: 0.03335869846865535 times: 0.12887825816869736\n",
      "epoch: 32 loss: 0.032312463223934176 times: 0.1284419478792133\n",
      "epoch: 33 loss: 0.03160225445404649 times: 0.12795687423032873\n",
      "epoch: 34 loss: 0.0306625266186893 times: 0.12770375524248395\n",
      "epoch: 35 loss: 0.029758576173335313 times: 0.12749451398849487\n",
      "epoch: 36 loss: 0.02880936624482274 times: 0.12729782027167244\n",
      "epoch: 37 loss: 0.02810204353183508 times: 0.12708606218036853\n",
      "epoch: 38 loss: 0.02766701115295291 times: 0.12676197443252954\n",
      "epoch: 39 loss: 0.027263902463018894 times: 0.1265638828277588\n",
      "epoch: 40 loss: 0.026977634821087122 times: 0.1263956500262749\n",
      "epoch: 41 loss: 0.02638437720015645 times: 0.1262411219733102\n",
      "epoch: 42 loss: 0.025356671288609505 times: 0.12607642107231673\n",
      "epoch: 43 loss: 0.02463406227529049 times: 0.12588250637054443\n",
      "epoch: 44 loss: 0.023907284419983625 times: 0.1257291316986084\n",
      "epoch: 45 loss: 0.0235774346254766 times: 0.12574138848677927\n",
      "epoch: 46 loss: 0.02319094936363399 times: 0.12561044287174306\n",
      "epoch: 47 loss: 0.022623637532815336 times: 0.12549944718678793\n",
      "epoch: 48 loss: 0.022229495318606497 times: 0.12539896673085738\n",
      "epoch: 49 loss: 0.02182032125070691 times: 0.12526379585266112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lin): Linear(in_features=149, out_features=24, bias=True)\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=149, out_features=200, bias=True)\n",
       "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (5): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=200, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mle_net = Net(X_train[:,:-1], Y_train, [200,200]).to(DEVICE)\n",
    "train_mle_net(mle_net, params, X_train_pt, Y_train_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90155a03-142b-434b-a48f-43d7e303f010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rounds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a5ce4b2-dd4b-48d4-b96e-9bdf6e027fd6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  mean loss:  4.18284008365411  median  3.9846460819244385 cur:  1.5376639366149902\n",
      "epoch  1  mean loss:  2.721964291334152  median  2.080314874649048 cur:  1.2822952270507812\n",
      "epoch  2  mean loss:  1.30033556163311  median  1.5520480275154114 cur:  0.6649987697601318\n",
      "epoch  3  mean loss:  0.8545614406466484  median  1.2825250625610352 cur:  0.4993521571159363\n",
      "epoch  4  mean loss:  0.596975120306015  median  1.0081420540809631 cur:  0.46785664558410645\n",
      "epoch  5  mean loss:  0.45932706981897353  median  0.8250999748706818 cur:  0.42127329111099243\n",
      "epoch  6  mean loss:  0.38493684962391855  median  0.6994702219963074 cur:  0.3650592267513275\n",
      "epoch  7  mean loss:  0.3432394604384899  median  0.581022173166275 cur:  0.3170381188392639\n",
      "epoch  8  mean loss:  0.3199559146165848  median  0.5299622118473053 cur:  0.31474143266677856\n",
      "epoch  9  mean loss:  0.30364779233932493  median  0.47323331236839294 cur:  0.3098122179508209\n",
      "epoch  10  mean loss:  0.289999230504036  median  0.43795496225357056 cur:  0.30135393142700195\n",
      "epoch  11  mean loss:  0.2784970898926258  median  0.41254934668540955 cur:  0.3050829768180847\n",
      "epoch  12  mean loss:  0.2680591134727001  median  0.38928332924842834 cur:  0.296032190322876\n",
      "epoch  13  mean loss:  0.25889585331082343  median  0.3645712733268738 cur:  0.2894946038722992\n",
      "epoch  14  mean loss:  0.25069585964083674  median  0.3517082780599594 cur:  0.2837986648082733\n",
      "epoch  15  mean loss:  0.24291889265179634  median  0.33882132172584534 cur:  0.28396254777908325\n",
      "epoch  16  mean loss:  0.2356594029068947  median  0.32822051644325256 cur:  0.2853621244430542\n",
      "epoch  17  mean loss:  0.22975043907761575  median  0.31664249300956726 cur:  0.2726955711841583\n",
      "epoch  18  mean loss:  0.22440260961651803  median  0.30707162618637085 cur:  0.27556926012039185\n",
      "epoch  19  mean loss:  0.2191505640745163  median  0.2983198016881943 cur:  0.26584112644195557\n",
      "epoch  20  mean loss:  0.21433621510863304  median  0.2903454899787903 cur:  0.26048749685287476\n",
      "epoch  21  mean loss:  0.21019563302397729  median  0.2849180996417999 cur:  0.2611898183822632\n",
      "epoch  22  mean loss:  0.20760389685630798  median  0.2780338227748871 cur:  0.2607668340206146\n",
      "epoch  23  mean loss:  0.20351434573531152  median  0.27249307930469513 cur:  0.2568511962890625\n",
      "epoch  24  mean loss:  0.20016370043158532  median  0.26715876162052155 cur:  0.26034611463546753\n",
      "epoch  25  mean loss:  0.1971275167167187  median  0.26120805740356445 cur:  0.2522871792316437\n",
      "epoch  26  mean loss:  0.19346377439796925  median  0.2582640200853348 cur:  0.2461572140455246\n",
      "epoch  27  mean loss:  0.19048661403357983  median  0.2532735913991928 cur:  0.242610365152359\n",
      "epoch  28  mean loss:  0.18823595762252807  median  0.2497967779636383 cur:  0.24305546283721924\n",
      "epoch  29  mean loss:  0.18635907411575317  median  0.24556631594896317 cur:  0.2398565411567688\n",
      "epoch  30  mean loss:  0.1838437670469284  median  0.24181576073169708 cur:  0.23659241199493408\n",
      "epoch  31  mean loss:  0.18045128062367438  median  0.23929034173488617 cur:  0.23501881957054138\n",
      "epoch  32  mean loss:  0.1770003079622984  median  0.23652545362710953 cur:  0.23087701201438904\n",
      "epoch  33  mean loss:  0.1740463164448738  median  0.23340515792369843 cur:  0.21675227582454681\n",
      "epoch  34  mean loss:  0.17071812458336352  median  0.22995314747095108 cur:  0.22186319530010223\n",
      "epoch  35  mean loss:  0.16737628385424613  median  0.22772204130887985 cur:  0.21957612037658691\n",
      "epoch  36  mean loss:  0.16634148485958578  median  0.22472427040338516 cur:  0.222957581281662\n",
      "epoch  37  mean loss:  0.16469556123018264  median  0.22212207317352295 cur:  0.2093624472618103\n",
      "epoch  38  mean loss:  0.16064643688499927  median  0.21930739283561707 cur:  0.20402976870536804\n",
      "epoch  39  mean loss:  0.16104722149670125  median  0.2172916978597641 cur:  0.20241940021514893\n",
      "epoch  40  mean loss:  0.16022647567093373  median  0.21490232646465302 cur:  0.1927787959575653\n",
      "epoch  41  mean loss:  0.1554233857989311  median  0.2122967690229416 cur:  0.19348034262657166\n",
      "epoch  42  mean loss:  0.1536305958032608  median  0.20929700136184692 cur:  0.19251012802124023\n",
      "epoch  43  mean loss:  0.15265362367033958  median  0.2067169025540352 cur:  0.18870489299297333\n",
      "epoch  44  mean loss:  0.14950165957212447  median  0.2048160880804062 cur:  0.1831340193748474\n",
      "epoch  45  mean loss:  0.14684921532869338  median  0.2026624083518982 cur:  0.18252228200435638\n",
      "epoch  46  mean loss:  0.14477608658373356  median  0.2009636014699936 cur:  0.1864592730998993\n",
      "epoch  47  mean loss:  0.14314251482486726  median  0.19823889434337616 cur:  0.1814693659543991\n",
      "epoch  48  mean loss:  0.1410839568078518  median  0.19637108594179153 cur:  0.18108105659484863\n",
      "epoch  49  mean loss:  0.13879933416843415  median  0.1948879361152649 cur:  0.17904099822044373\n",
      "MEAN LOSS PROJECT NET:  0.13879933416843415\n"
     ]
    }
   ],
   "source": [
    "projectnet = ProjectNet(A, b, 24, rounds=rounds).to(DEVICE)\n",
    "train_projectnet(projectnet, mle_net(X_train_pt).detach(), params, epochs=50, verbose=True)\n",
    "torch.save(projectnet.state_dict(), \"saved_models/projectnet{}.pt\".format(params['c_ramp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5a4e160-8b8d-4a30-9769-2d5fd21a7317",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved_models/projectnet0.1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# projectnet = ProjectNet(A, b, 24, rounds=5).to(DEVICE)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m projectnet\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_models/projectnet0.1.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/my-conda-envs/rares_env/lib/python3.12/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/my-conda-envs/rares_env/lib/python3.12/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/my-conda-envs/rares_env/lib/python3.12/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_models/projectnet0.1.pt'"
     ]
    }
   ],
   "source": [
    "# projectnet = ProjectNet(A, b, 24, rounds=5).to(DEVICE)\n",
    "# projectnet.load_state_dict(torch.load(\"saved_models/projectnet{}.pt\".format(params['c_ramp'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c2063c5-bfc5-4648-a589-d2852252b9a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  mean loss:  3.9755948392244487  median  3.781075954437256 cur:  1.3339604139328003\n",
      "epoch  1  mean loss:  2.6845109701156615  median  2.1006016731262207 cur:  1.1829404830932617\n",
      "epoch  2  mean loss:  1.4345572209358215  median  1.6450846195220947 cur:  0.7328975200653076\n",
      "epoch  3  mean loss:  1.1463060581684112  median  1.4490913152694702 cur:  0.5920180082321167\n",
      "epoch  4  mean loss:  0.9871708887815476  median  1.3116450309753418 cur:  0.46538084745407104\n",
      "epoch  5  mean loss:  0.8187243214249611  median  1.177674412727356 cur:  0.3478233218193054\n",
      "epoch  6  mean loss:  0.7040427184104919  median  1.068730354309082 cur:  0.3444867730140686\n",
      "epoch  7  mean loss:  0.617328149676323  median  0.9836393892765045 cur:  0.25425514578819275\n",
      "epoch  8  mean loss:  0.5436446094512939  median  0.8949326872825623 cur:  0.21643410623073578\n",
      "epoch  9  mean loss:  0.5189338359236717  median  0.8517062962055206 cur:  0.2465420365333557\n",
      "epoch  10  mean loss:  0.49954450339078904  median  0.7858456671237946 cur:  0.19947104156017303\n",
      "epoch  11  mean loss:  0.4725271058082581  median  0.7382298409938812 cur:  0.18636879324913025\n",
      "epoch  12  mean loss:  0.4520257875323296  median  0.7058022320270538 cur:  0.17258332669734955\n",
      "epoch  13  mean loss:  0.4339626654982567  median  0.6696077287197113 cur:  0.16010764241218567\n",
      "epoch  14  mean loss:  0.41841632544994356  median  0.6370914578437805 cur:  0.14925892651081085\n",
      "epoch  15  mean loss:  0.40622491866350174  median  0.6190213263034821 cur:  0.14244617521762848\n",
      "epoch  16  mean loss:  0.39536726251244547  median  0.5937779247760773 cur:  0.13488760590553284\n",
      "epoch  17  mean loss:  0.3853509403765202  median  0.5747574865818024 cur:  0.12984177470207214\n",
      "epoch  18  mean loss:  0.3764897122979164  median  0.5579773485660553 cur:  0.12808597087860107\n",
      "epoch  19  mean loss:  0.3684433850646019  median  0.5442444682121277 cur:  0.12532827258110046\n",
      "epoch  20  mean loss:  0.3599830438196659  median  0.5296241044998169 cur:  0.12385056912899017\n",
      "epoch  21  mean loss:  0.352449214309454  median  0.5163561105728149 cur:  0.11923801898956299\n",
      "epoch  22  mean loss:  0.34565790861845014  median  0.5044669806957245 cur:  0.11655732989311218\n",
      "epoch  23  mean loss:  0.3388824544101954  median  0.4950898587703705 cur:  0.11378264427185059\n",
      "epoch  24  mean loss:  0.332331690788269  median  0.483763188123703 cur:  0.1124773621559143\n",
      "epoch  25  mean loss:  0.3256113188713789  median  0.47576263546943665 cur:  0.11110860109329224\n",
      "epoch  26  mean loss:  0.3188949527591467  median  0.4668503850698471 cur:  0.10830798000097275\n",
      "epoch  27  mean loss:  0.3127886065095663  median  0.45674750208854675 cur:  0.11042788624763489\n",
      "epoch  28  mean loss:  0.30828334249556066  median  0.44952093064785004 cur:  0.11153930425643921\n",
      "epoch  29  mean loss:  0.30192087635397913  median  0.44187304377555847 cur:  0.10681971162557602\n",
      "epoch  30  mean loss:  0.29428392633795736  median  0.43411585688591003 cur:  0.10817747563123703\n",
      "epoch  31  mean loss:  0.2886016081273556  median  0.42666563391685486 cur:  0.10797598958015442\n",
      "epoch  32  mean loss:  0.2827194868773222  median  0.41849252581596375 cur:  0.10840099304914474\n",
      "epoch  33  mean loss:  0.27629824824631216  median  0.4126647263765335 cur:  0.10918217152357101\n",
      "epoch  34  mean loss:  0.2705865953117609  median  0.4056241065263748 cur:  0.10856296122074127\n",
      "epoch  35  mean loss:  0.2654766377806663  median  0.3998914659023285 cur:  0.10892864316701889\n",
      "epoch  36  mean loss:  0.26025291323661803  median  0.3937879055738449 cur:  0.11045713722705841\n",
      "epoch  37  mean loss:  0.25638004526495933  median  0.3864952325820923 cur:  0.11986653506755829\n",
      "epoch  38  mean loss:  0.25286666214466097  median  0.37992002069950104 cur:  0.11793267726898193\n",
      "epoch  39  mean loss:  0.24862069569528103  median  0.3751373589038849 cur:  0.12002347409725189\n",
      "epoch  40  mean loss:  0.24530529789626598  median  0.3694329708814621 cur:  0.118894562125206\n",
      "epoch  41  mean loss:  0.24172457449138166  median  0.3635663837194443 cur:  0.11706642806529999\n",
      "epoch  42  mean loss:  0.23741554737091064  median  0.35856370627880096 cur:  0.11961394548416138\n",
      "epoch  43  mean loss:  0.23432617783546447  median  0.35351884365081787 cur:  0.10312151908874512\n",
      "epoch  44  mean loss:  0.23016050800681115  median  0.3481875956058502 cur:  0.11271121352910995\n",
      "epoch  45  mean loss:  0.22457473568618297  median  0.34498366713523865 cur:  0.10638266801834106\n",
      "epoch  46  mean loss:  0.22110999286174773  median  0.3403436839580536 cur:  0.11739903688430786\n",
      "epoch  47  mean loss:  0.21879311956465244  median  0.3368114233016968 cur:  0.106904998421669\n",
      "epoch  48  mean loss:  0.21775009632110595  median  0.332535058259964 cur:  0.1071072518825531\n",
      "epoch  49  mean loss:  0.21669432386755944  median  0.32740655541419983 cur:  0.10202424228191376\n",
      "MEAN LOSS PROJECT NET:  0.21669432386755944\n",
      "epoch  0  mean loss:  0.2677797841338011 time 1.7692980766296387\n",
      "test: 0.23773498088121414\n",
      "epoch  1  mean loss:  0.18561703597123808 time 1.7950570583343506\n",
      "test: 0.1906937857468923\n",
      "epoch  2  mean loss:  0.16959063995342988 time 1.8030258814493816\n",
      "test: 0.18763836224873862\n",
      "epoch  3  mean loss:  0.15992124034808233 time 1.7932566404342651\n",
      "test: 0.1837457170089086\n",
      "epoch  4  mean loss:  0.15123884437175897 time 1.788786268234253\n",
      "test: 0.16946479678153992\n",
      "epoch  5  mean loss:  0.1463000361736004 time 1.7760487000147502\n",
      "test: 0.16946008801460266\n",
      "epoch  6  mean loss:  0.1406072315115195 time 1.7733722073691232\n",
      "test: 0.1713880846897761\n",
      "epoch  7  mean loss:  0.13897117800437486 time 1.7682321965694427\n",
      "test: 0.1718034123380979\n",
      "epoch  8  mean loss:  0.1344810864673211 time 1.772516409556071\n",
      "test: 0.15895449370145798\n",
      "epoch  9  mean loss:  0.13822197541594505 time 1.7597754716873169\n",
      "test: 0.16001257300376892\n",
      "epoch  10  mean loss:  0.13419008541565675 time 1.7587639418515293\n",
      "test: 0.16487416625022888\n",
      "epoch  11  mean loss:  0.13021715701772615 time 1.7557058135668437\n",
      "test: 0.1562939335902532\n",
      "epoch  12  mean loss:  0.12978843198372766 time 1.7553212826068585\n",
      "test: 0.16050052642822266\n",
      "epoch  13  mean loss:  0.13650288289556137 time 1.756196413721357\n",
      "test: 0.16581772764523825\n",
      "epoch  14  mean loss:  0.128077227049149 time 1.7622402509053547\n",
      "test: 0.1591658890247345\n",
      "epoch  15  mean loss:  0.1274557767006067 time 1.762883484363556\n",
      "test: 0.15029361099004745\n",
      "epoch  16  mean loss:  0.12418618483039048 time 1.7616241679472082\n",
      "test: 0.15040806432565054\n",
      "epoch  17  mean loss:  0.1247765224140424 time 1.7612823645273845\n",
      "test: 0.1421725352605184\n",
      "epoch  18  mean loss:  0.11917233581726368 time 1.7644694729855186\n",
      "test: 0.15286749601364136\n",
      "epoch  19  mean loss:  0.11998708660785969 time 1.7656577587127686\n",
      "test: 0.14988490690787634\n",
      "epoch  20  mean loss:  0.12441384677703564 time 1.7659385771978469\n",
      "test: 0.14889446397622427\n",
      "epoch  21  mean loss:  0.12007382483436511 time 1.7678963487798518\n",
      "test: 0.14903158446153006\n",
      "epoch  22  mean loss:  0.12146610422776295 time 1.7695624413697615\n",
      "test: 0.15008894354104996\n",
      "epoch  23  mean loss:  0.12523611147816366 time 1.7656348049640656\n",
      "test: 0.1447677438457807\n",
      "epoch  24  mean loss:  0.11743138272028703 time 1.7678902244567871\n",
      "test: 0.1425269196430842\n",
      "epoch  25  mean loss:  0.11345351888583256 time 1.7649241135670588\n",
      "test: 0.1551497479279836\n",
      "epoch  26  mean loss:  0.11141609572447263 time 1.7653368755623147\n",
      "test: 0.14449094980955124\n",
      "epoch  27  mean loss:  0.11496856063604355 time 1.7660709874970573\n",
      "test: 0.14534099648396173\n",
      "epoch  28  mean loss:  0.11299247896442047 time 1.764598114737149\n",
      "test: 0.14255745708942413\n",
      "epoch  29  mean loss:  0.1118994693343456 time 1.764012130101522\n",
      "test: 0.1347558672229449\n",
      "epoch  30  mean loss:  0.11519927216263917 time 1.7664529815796883\n",
      "test: 0.14415906618038812\n",
      "epoch  31  mean loss:  0.11483673722698139 time 1.7685693725943565\n",
      "test: 0.15367928395668665\n",
      "epoch  32  mean loss:  0.11747237868033923 time 1.7711323319059429\n",
      "test: 0.14553041011095047\n",
      "epoch  33  mean loss:  0.12298153082911785 time 1.7718471919789034\n",
      "test: 0.13383099933465323\n",
      "epoch  34  mean loss:  0.11565721722749564 time 1.7723119735717774\n",
      "test: 0.14368540793657303\n",
      "epoch  35  mean loss:  0.12256121291564061 time 1.774266050921546\n",
      "test: 0.14746629695097604\n",
      "epoch  36  mean loss:  0.1278710952745034 time 1.7761037800763104\n",
      "test: 0.1607085441549619\n",
      "epoch  37  mean loss:  0.13137705967976496 time 1.7753537328619706\n",
      "test: 0.15011307348807654\n",
      "epoch  38  mean loss:  0.12286349185384236 time 1.775363530868139\n",
      "test: 0.13819916049639383\n",
      "epoch  39  mean loss:  0.1157136456324504 time 1.7749960720539093\n",
      "test: 0.14466665188471475\n",
      "epoch  40  mean loss:  0.12322640189757714 time 1.7761567453058755\n",
      "test: 0.15238185226917267\n",
      "epoch  41  mean loss:  0.11556970414060813 time 1.778038081668672\n",
      "test: 0.164211576183637\n",
      "epoch  42  mean loss:  0.11663079319091943 time 1.780871723973474\n",
      "test: 0.15674296766519547\n",
      "epoch  43  mean loss:  0.1120867571578576 time 1.7839705077084629\n",
      "test: 0.14790011445681253\n",
      "epoch  44  mean loss:  0.10823517407362278 time 1.786353381474813\n",
      "test: 0.14089821775754294\n",
      "epoch  45  mean loss:  0.10572819956220113 time 1.7865529008533643\n",
      "test: 0.1372170423467954\n",
      "epoch  46  mean loss:  0.10646865688837491 time 1.7889526194714485\n",
      "test: 0.13011589149634042\n",
      "epoch  47  mean loss:  0.10630739422944877 time 1.7918941626946132\n",
      "test: 0.13764806340138117\n",
      "epoch  48  mean loss:  0.10901087006697288 time 1.7936748533832783\n",
      "test: 0.14131978650887808\n",
      "epoch  49  mean loss:  0.10625618151747264 time 1.7957091951370239\n",
      "test: 0.13922438770532608\n"
     ]
    }
   ],
   "source": [
    "# projectnet.eval()\n",
    "# model_pnet = Net(X_train[:,:-1], Y_train, [200,200]).to(DEVICE)\n",
    "# train_with_pnet(model_pnet, projectnet, X_train_pt, Y_train_pt, params, rounds=rounds, epochs=50, lr=1e-4)\n",
    "\n",
    "projectnet = ProjectNet(A, b, 24, rounds=rounds).to(DEVICE)\n",
    "train_projectnet(projectnet, model_pnet(X_train_pt).detach(), params, epochs=50, verbose=True)\n",
    "torch.save(projectnet.state_dict(), \"saved_models/projectnet{}.pt\".format(params['c_ramp']))\n",
    "\n",
    "train_with_pnet(model_pnet, projectnet, X_train_pt, Y_train_pt, X_test_pt, Y_test_pt, params, rounds=rounds, epochs=50, lr=1e-4)\n",
    "torch.save(model_pnet.state_dict(), \"saved_models/model_pnet{}.pt\".format(params['c_ramp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93f68a2f-c551-4371-b64b-717de9d9896e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_pnet = Net(X_train[:,:-1], Y_train, [200,200]).to(DEVICE)\n",
    "# model_pnet.load_state_dict(torch.load(\"saved_models/model_pnet{}.pt\".format(params['c_ramp'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "576f9ef8-e726-49af-8f6e-c8ac9425c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_costs = []\n",
    "batch_size = 100\n",
    "for k in range(X_test_pt.shape[0] // batch_size):\n",
    "    p = model_pnet(X_test_pt[k:k+batch_size,:]).detach()\n",
    "    d = projectnet(p, rounds=5)\n",
    "    cost_test = task_loss_no_mean(d, Y_test_pt[k:k+batch_size,:], params).detach().cpu().numpy()\n",
    "    net_costs.append(cost_test)\n",
    "    # test_costs.append(cost_test.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b40292e-947f-4430-a59a-3091cde953c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12967134"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584212a-c009-4123-a3cd-f736499cafbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dddde1dd-3211-47a4-960b-4c49c0956d92",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 2.3861129613132053 times: 24.14952540397644\n",
      "epoch: 1 loss: 2.1324610537095916 times: 23.861863136291504\n",
      "epoch: 2 loss: 1.9182594444097503 times: 23.7902729511261\n",
      "epoch: 3 loss: 1.6996734061814711 times: 24.037619590759277\n",
      "epoch: 4 loss: 1.3475223767746587 times: 23.965864896774292\n",
      "epoch: 5 loss: 1.0768389630970947 times: 23.944028735160828\n",
      "epoch: 6 loss: 0.8743361698029382 times: 23.86519401414054\n",
      "epoch: 7 loss: 0.7175933306379032 times: 23.74442908167839\n",
      "epoch: 8 loss: 0.6053115277078343 times: 23.736521032121445\n",
      "epoch: 9 loss: 0.5282188725486012 times: 23.688804364204408\n",
      "epoch: 10 loss: 0.4696702816457084 times: 23.784093488346446\n",
      "epoch: 11 loss: 0.4312673042086059 times: 23.800779183705647\n",
      "epoch: 12 loss: 0.40697264646592557 times: 23.800506976934578\n",
      "epoch: 13 loss: 0.3848881525097938 times: 23.80308427129473\n",
      "epoch: 14 loss: 0.3756143836876597 times: 23.905430666605632\n",
      "epoch: 15 loss: 0.37408408260234366 times: 23.87533275783062\n",
      "epoch: 16 loss: 0.36698700728811107 times: 23.897752130732815\n",
      "epoch: 17 loss: 0.3625363060863412 times: 23.888027522299026\n",
      "epoch: 18 loss: 0.3532223467306929 times: 23.90673690093191\n",
      "epoch: 19 loss: 0.35275682375459744 times: 23.921704614162444\n",
      "epoch: 20 loss: 0.3486184785872075 times: 24.04743728183565\n",
      "epoch: 21 loss: 0.3408774511924737 times: 24.07129769975489\n",
      "epoch: 22 loss: 0.3386999055767611 times: 24.138573833133865\n",
      "epoch: 23 loss: 0.33506697968426 times: 24.12833335995674\n",
      "epoch: 24 loss: 0.32915076548227623 times: 24.12786915779114\n",
      "epoch: 25 loss: 0.3259142875876262 times: 24.150971009181095\n",
      "epoch: 26 loss: 0.31693198433708 times: 24.162446445888943\n",
      "epoch: 27 loss: 0.3131686358998592 times: 24.232134810515813\n",
      "epoch: 28 loss: 0.314419587682065 times: 24.24832826647265\n",
      "epoch: 29 loss: 0.3085274684522228 times: 24.24983172416687\n",
      "epoch: 30 loss: 0.30311878529533876 times: 24.232266333795362\n",
      "epoch: 31 loss: 0.2985558401742097 times: 24.19790966808796\n",
      "epoch: 32 loss: 0.303463627072154 times: 24.196961865280613\n",
      "epoch: 33 loss: 0.30578612680857864 times: 24.207803578937757\n",
      "epoch: 34 loss: 0.30933494537011713 times: 24.21648963519505\n",
      "epoch: 35 loss: 0.3071966446295016 times: 24.212138560083176\n",
      "epoch: 36 loss: 0.29837376950918987 times: 24.218490465267283\n",
      "epoch: 37 loss: 0.2966001548727521 times: 24.201963223909075\n",
      "epoch: 38 loss: 0.29165252294213956 times: 24.195124558913403\n",
      "epoch: 39 loss: 0.29142975818558803 times: 24.227353751659393\n",
      "epoch: 40 loss: 0.289960434350237 times: 24.243545014683793\n",
      "epoch: 41 loss: 0.2918211493832662 times: 24.239025172733125\n",
      "epoch: 42 loss: 0.2928579239263536 times: 24.253135492635327\n",
      "epoch: 43 loss: 0.2950301973133726 times: 24.283430224115197\n",
      "epoch: 44 loss: 0.2970899888015202 times: 24.284937816196017\n",
      "epoch: 45 loss: 0.2895157488822797 times: 24.293769483980924\n",
      "epoch: 46 loss: 0.28319562331249376 times: 24.292973432135074\n",
      "epoch: 47 loss: 0.2780958886347168 times: 24.310347606738407\n",
      "epoch: 48 loss: 0.2781545239656588 times: 24.33110390877237\n",
      "epoch: 49 loss: 0.2760980749715141 times: 24.34164837837219\n"
     ]
    }
   ],
   "source": [
    "task_net = Net2(X_train[:,:-1], Y_train, [200,200]).to(DEVICE)\n",
    "train_task_net(task_net, params, X_train_pt, Y_train_pt)\n",
    "torch.save(task_net.state_dict(), \"saved_models/task_net.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25eab28f-bead-4826-8e80-67f2b65cf04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_results = np.load(\"task_results.npy\")\n",
    "mle_results = np.load(\"mle_results.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "638fd0e0-452d-4c1a-af7f-756ad32c7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_task, s_task = task_net(X_test_pt)\n",
    "d_task = dist_solver(p_task, s_task).detach()\n",
    "cost_task = task_loss_no_mean(d_task, Y_test_pt, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3b44778-b030-4c91-b1c5-e9641cd14de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 24)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_costs=np.array(net_costs).reshape(600,24)\n",
    "net_costs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e4fa48-7797-479d-8f0c-6d2b820766b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(24), np.mean(net_costs,axis=0), label='pnet')\n",
    "# plt.plot(range(24), cost_task.mean(0).cpu().numpy(), label='task')\n",
    "plt.plot(range(24), task_results[:600,:].mean(0), label='task')\n",
    "# plt.plot(range(24), mle_results.mean(0), label='mle')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6483d0e5-79e0-4760-8c8a-2939804ca245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1000, device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(d[:,:23] - d[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d189ce5-1d35-4a2a-8ea3-94df21aa9b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13162148"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce860d08-f0db-427b-90b1-b79145d560c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12967134"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_costs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "659f2e38-07b6-4cb9-bbe8-c8cdfe96834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"pnet_results.npy\", net_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66d0d7c3-2530-424b-b1ce-fb7d3b82a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model_pnet, projectnet):\n",
    "    pnet_results = []\n",
    "    for _ in range(10):\n",
    "        net_costs = []\n",
    "        for k in range(X_test_pt.shape[0] // batch_size):\n",
    "            p = model_pnet(X_test_pt[k:k+batch_size,:]).detach()\n",
    "            d = projectnet(p, rounds=rounds)\n",
    "            cost_test = task_loss_no_mean(d, Y_test_pt[k:k+batch_size,:], params).detach().cpu().numpy()\n",
    "            net_costs.append(cost_test)\n",
    "        net_costs = np.array(net_costs).reshape(600,24)\n",
    "        pnet_results.append(net_costs)\n",
    "    pnet_results = np.array(pnet_results) \n",
    "    print(pnet_results[0,:])\n",
    "    print(pnet_results[1,:])\n",
    "    return np.mean(pnet_results, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "372b92f3-b9b0-4ebe-84a5-e1828159d7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05169624 0.07740811 0.04036757 ... 0.18670538 0.22773585 0.17829044]\n",
      " [0.03361551 0.07978    0.03180664 ... 0.2716348  0.2717738  0.2556494 ]\n",
      " [0.09123388 0.5361624  0.16456479 ... 0.17476866 0.6277769  0.27443156]\n",
      " ...\n",
      " [0.0993123  0.1033532  0.07622579 ... 0.17429772 0.23094335 0.17656286]\n",
      " [0.07711309 0.08715592 0.0680978  ... 0.18661842 0.22768489 0.19754732]\n",
      " [0.07843082 0.06296031 0.06554107 ... 0.13948129 0.16330463 0.14074664]]\n",
      "[[0.05169624 0.07740811 0.04036757 ... 0.18670538 0.22773585 0.17829044]\n",
      " [0.03361551 0.07978    0.03180664 ... 0.2716348  0.2717738  0.2556494 ]\n",
      " [0.09123388 0.5361624  0.16456479 ... 0.17476866 0.6277769  0.27443156]\n",
      " ...\n",
      " [0.0993123  0.1033532  0.07622579 ... 0.17429772 0.23094335 0.17656286]\n",
      " [0.07711309 0.08715592 0.0680978  ... 0.18661842 0.22768489 0.19754732]\n",
      " [0.07843082 0.06296031 0.06554107 ... 0.13948129 0.16330463 0.14074664]]\n"
     ]
    }
   ],
   "source": [
    "net_costs=eval_model(model_pnet, projectnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa162ff2-bb2d-410d-a088-bc3eada90297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05169624, 0.0774081 , 0.04036757, ..., 0.18670537, 0.22773585,\n",
       "        0.17829046],\n",
       "       [0.03361552, 0.07978   , 0.03180664, ..., 0.2716348 , 0.2717738 ,\n",
       "        0.25564936],\n",
       "       [0.09123387, 0.5361624 , 0.1645648 , ..., 0.17476867, 0.627777  ,\n",
       "        0.27443153],\n",
       "       ...,\n",
       "       [0.0993123 , 0.1033532 , 0.07622578, ..., 0.1742977 , 0.23094335,\n",
       "        0.17656288],\n",
       "       [0.07711309, 0.08715592, 0.06809781, ..., 0.18661843, 0.22768489,\n",
       "        0.19754732],\n",
       "       [0.07843082, 0.06296032, 0.06554108, ..., 0.13948129, 0.16330461,\n",
       "        0.14074662]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18fe3352-91b7-4ab9-9cb1-279dbb0f2a83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cplex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcplex\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cplex'"
     ]
    }
   ],
   "source": [
    "import cplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45f0ef12-79d9-4a5f-9c0c-64d19a3e9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4190230b-8378-4819-9da2-bbe9315303a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rares_env",
   "language": "python",
   "name": "rares_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
